{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6175afe",
   "metadata": {},
   "source": [
    "## DeepSORT Tracking\n",
    "\n",
    "### Introduction\n",
    "This jupyter notebook runs a DeepSORT Algorithm atop of various object detection (bounding box) models to track objects in video files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd91dc5",
   "metadata": {},
   "source": [
    "## Install Python Dependencies\n",
    "\n",
    "Python Version Used: 3.7 =< version =< 3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe4a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tensorflow==2.5.0\n",
    "!pip install -U numpy==1.18.5\n",
    "!pip install -U Pillow==7.2.0\n",
    "!pip install -U opencv-python==4.5.1.48\n",
    "!pip install -U flask==2.1.2\n",
    "!pip install -U tf-slim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d81c47",
   "metadata": {},
   "source": [
    "## Import Python Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import os.path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%cd deep_sort_realtime\n",
    "from PIL import Image\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6388c29a",
   "metadata": {},
   "source": [
    "## Load Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a998d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label(model_path):\n",
    "    \"\"\"Reads label map in the format of .pbtxt and parse into dictionary\n",
    "\n",
    "    Args:\n",
    "        label_map_path: the file path to the label_map\n",
    "\n",
    "    Returns:\n",
    "        dictionary with the format of {label_index: {'id': label_index, 'name': label_name}}\n",
    "    \"\"\"\n",
    "    label_map_path = os.path.join(model_path, \"label_map.pbtxt\")\n",
    "\n",
    "    if os.path.exists(label_map_path) is False:\n",
    "        raise FileNotFoundError(\"No valid label map found.\")\n",
    "\n",
    "    label_map = {}\n",
    "\n",
    "    with open(label_map_path, \"r\") as label_file:\n",
    "        for line in label_file:\n",
    "            if \"id\" in line:\n",
    "                label_index = int(line.split(\":\")[-1])\n",
    "                label_name = next(label_file).split(\":\")[-1].strip().strip(\"'\")\n",
    "                label_map[label_index] = {\"id\": label_index, \"name\": label_name}\n",
    "\n",
    "    return label_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee960ecc",
   "metadata": {},
   "source": [
    "## Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(img, height, width):\n",
    "    \"\"\"Load an image from base64 into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "        image_base64: image in base64 format\n",
    "        height: height of image\n",
    "        width: width of image\n",
    "\n",
    "    Returns:\n",
    "        uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    image_shape = np.asarray(img).shape\n",
    "\n",
    "    image_resized = img.resize((height, width))\n",
    "    return np.array(image_resized), (image_shape[0], image_shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a706a",
   "metadata": {},
   "source": [
    "## Prediction Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0a37e4",
   "metadata": {},
   "source": [
    "### Bounding Box Tensorflow Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d0993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_tf_predition(img, trained_model, size, threshold):\n",
    "    \"\"\"Run prediction on image in base64 format with trained tf bounding box model and label.\n",
    "\n",
    "    Args:\n",
    "        img: input image\n",
    "        trained_model: loaded tensorflow model.\n",
    "        size: size of image to load.\n",
    "        threshold: confidence threshold.\n",
    "\n",
    "    Returns:\n",
    "        list for detection in the format of\n",
    "        [(boxes,classes,scores)...]\n",
    "        boxes: Array of array contains normalized boxes coorindates,\n",
    "        classes: Array of numbers representing class,\n",
    "        scores: Array of numbers representing confidence scores\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ## Run prediction\n",
    "    height, width = size.split(\",\")\n",
    "\n",
    "    ## Returned original_shape is in the format of width, height\n",
    "    image_resized, origi_shape = load_image_into_numpy_array(\n",
    "        img, int(height), int(width)\n",
    "    )\n",
    "\n",
    "    ## The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image_resized)\n",
    "\n",
    "    ## The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    ## Feed image into model\n",
    "    detections_output = trained_model(input_tensor)\n",
    "\n",
    "    num_detections = int(detections_output.pop(\"num_detections\"))\n",
    "    detections = {\n",
    "        key: value[0, :num_detections].numpy()\n",
    "        for key, value in detections_output.items()\n",
    "    }\n",
    "    detections[\"num_detections\"] = num_detections\n",
    "\n",
    "    ## Filter out predictions below threshold\n",
    "    indexes = np.where(detections[\"detection_scores\"] > float(threshold))\n",
    "\n",
    "    ## Extract predictions\n",
    "    bboxes = detections[\"detection_boxes\"][indexes]\n",
    "    classes = detections[\"detection_classes\"][indexes].astype(np.int64)\n",
    "    scores = detections[\"detection_scores\"][indexes]\n",
    "    detection_info = {\n",
    "        \"boxes\": bboxes.tolist(),\n",
    "        \"classes\": classes.tolist(),\n",
    "        \"scores\": scores.tolist(),\n",
    "    }\n",
    "    if len(detection_info[\"boxes\"]) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        detection_out = []\n",
    "        for i in range(0, len(detection_info[\"boxes\"])):\n",
    "            temp_box = [0, 0, 0, 0]\n",
    "            temp_box[3] = (\n",
    "                detection_info[\"boxes\"][i][2] - detection_info[\"boxes\"][i][0]\n",
    "            ) * origi_shape[0]\n",
    "            temp_box[2] = (\n",
    "                detection_info[\"boxes\"][i][3] - detection_info[\"boxes\"][i][1]\n",
    "            ) * origi_shape[1]\n",
    "            temp_box[1] = detection_info[\"boxes\"][i][0] * origi_shape[0]\n",
    "            temp_box[0] = detection_info[\"boxes\"][i][1] * origi_shape[1]\n",
    "\n",
    "            detection_out.append(\n",
    "                (temp_box, detection_info[\"scores\"][i], detection_info[\"classes\"][i])\n",
    "            )\n",
    "\n",
    "    return detection_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a57ae95",
   "metadata": {},
   "source": [
    "## DeepSORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ae0a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepSORT(\n",
    "    video_path, model_path, size, threshold, output_format, output_vid_trk_path, COLORS\n",
    "):\n",
    "\n",
    "    # load model\n",
    "    trained_model = tf.saved_model.load(os.path.join(model_path, \"saved_model\"))\n",
    "\n",
    "    # load map\n",
    "    category_index = load_label(model_path)\n",
    "\n",
    "    # read in video\n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # initialize video writer\n",
    "    width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
    "    codec = cv2.VideoWriter_fourcc(*output_format)\n",
    "    out = cv2.VideoWriter(output_vid_trk_path, codec, fps, (width, height))\n",
    "\n",
    "    # initialize tracker\n",
    "    tracker = DeepSort(\n",
    "        max_age=100,\n",
    "        nn_budget=20,\n",
    "        nms_max_overlap=0.3,\n",
    "        override_track_class=None,\n",
    "        trained_model=os.path.join(model_path, \"saved_model\"),\n",
    "    )\n",
    "\n",
    "    idx = 0\n",
    "    while True:\n",
    "        # Read Video\n",
    "        (grabbed, frame) = vid.read()\n",
    "        if not grabbed:\n",
    "            break\n",
    "\n",
    "        # Do detection on every video frame\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        prediction = bbox_tf_predition(\n",
    "            Image.fromarray(frame), trained_model, size, threshold\n",
    "        )\n",
    "\n",
    "        # the mobilenet detection function \"predict()\" should output bounding boxes, score, and class name\n",
    "        # instead of only image data.\n",
    "\n",
    "        if prediction == None:\n",
    "            result = np.asarray(frame)\n",
    "            result = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            out.write(result)\n",
    "            print(\"Frame \" + str(idx) + \" is written!\")\n",
    "            idx += 1\n",
    "            continue\n",
    "\n",
    "        tracks = tracker.update_tracks(prediction, frame=frame)\n",
    "\n",
    "        # update tracks\n",
    "        for track in tracks:\n",
    "            bbox = track.to_tlbr(oori=True)\n",
    "            if bbox is None:\n",
    "                continue\n",
    "\n",
    "            class_name = category_index[int(track.det_class)][\"name\"].strip('\"')\n",
    "            color = tuple(int(c) for c in COLORS[int(track.track_id) % len(COLORS)])\n",
    "\n",
    "            # draw bbox on screen\n",
    "            cv2.rectangle(\n",
    "                frame,\n",
    "                (\n",
    "                    int(bbox[0]),\n",
    "                    int(bbox[1]),\n",
    "                ),\n",
    "                (\n",
    "                    int(bbox[2]),\n",
    "                    int(bbox[3]),\n",
    "                ),\n",
    "                color,\n",
    "                int((width + height) / 600),\n",
    "            )\n",
    "            ## Draw label background\n",
    "            cv2.rectangle(\n",
    "                frame,\n",
    "                (\n",
    "                    int(bbox[0]),\n",
    "                    int(bbox[3]),\n",
    "                ),\n",
    "                (\n",
    "                    int(bbox[2]),\n",
    "                    int(bbox[3] + int((width + height) / 108)),\n",
    "                ),\n",
    "                color,\n",
    "                -1,\n",
    "            )\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                class_name,\n",
    "                (int(bbox[0]), int(bbox[3] + int((width + height) / 300))),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                (width + height) / 7500,\n",
    "                (0, 0, 0),\n",
    "                int((width + height) / 3000),\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                \"ID:\" + str(track.track_id),\n",
    "                (int(bbox[0]), int(bbox[3] + int((width + height) / 136))),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                (width + height) / 7500,\n",
    "                (0, 0, 0),\n",
    "                int((width + height) / 3000),\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "        result = np.asarray(frame)\n",
    "        result = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        # save video\n",
    "        out.write(result)\n",
    "        print(\"Frame \" + str(idx) + \" is written!\")\n",
    "        idx += 1\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    vid.release()\n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcd3ef5",
   "metadata": {},
   "source": [
    "## Run DeepSORT for Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616de082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_path = \"./pexels-rodnae-productions-5699922.mp4\"\n",
    "model_path = \"./model\"\n",
    "output_vid_trk_path = \"./output_\" + video_path.split(\"./\")[1].split(\".\")[0] + \".mp4\"\n",
    "size = \"320,320\"\n",
    "threshold = \"0.7\"\n",
    "output_format = \"mp4v\"\n",
    "COLORS = np.random.randint(0, 255, size=(200, 3))\n",
    "\n",
    "start = time.time()\n",
    "output_vid = DeepSORT(\n",
    "    video_path, model_path, size, threshold, output_format, output_vid_trk_path, COLORS\n",
    ")\n",
    "end = time.time()\n",
    "print(\n",
    "    \"Tracking by DeepSORT for \" + video_path + \" takes \" + str(int(end - start)) + \"s.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da05fb4f",
   "metadata": {},
   "source": [
    "## Display Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691cc3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "\n",
    "def display_video(path):\n",
    "    mp4 = open(path, \"rb\").read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "    display(\n",
    "        HTML(\n",
    "            \"\"\"\n",
    "          <video width=400 controls>\n",
    "                <source src=\"%s\" type=\"video/mp4\">\n",
    "          </video>\n",
    "      \"\"\"\n",
    "            % data_url\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9195e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_video(output_vid_trk_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95a22eaad15357b8581a3e85dc7deb44b392b83f2a0c98c7572069d11874febe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

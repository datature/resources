{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning Demo with Datature Inference API and Datature SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*-coding:utf-8 -*-\n",
    "\"\"\"\n",
    "  ████\n",
    "██    ██   Datature\n",
    "  ██  ██   Powering Breakthrough AI\n",
    "    ██\n",
    " \n",
    "@File    :   active_learning_demo.ipynb\n",
    "@Author  :   Leonard So & Wei Loon Cheng\n",
    "@Version :   1.0\n",
    "@Contact :   hello@datature.io\n",
    "@License :   Apache License 2.0\n",
    "@Desc    :   Active Learning Demo with Datature Inference API and Datature SDK\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook is an introduction of how you can use the Datature [Inference API](https://www.datature.io/blog/how-to-use-api-deployment-for-trained-model-inference) to perform active learning. When using your trained model deployed on our servers to run inference on an image, you can use our active learning metric to identify any predictions that are inaccurate or misclassified. Entropy values are calculated for the predictions, and the image will be uploaded to your project for manual annotation and re-training if the entropy value exceeds a certain threshold. To learn more about the active learning metric and other routines that you can utilize in our Inference API, do check out our [developer docs](https://developers.datature.io/docs/making-api-calls-to-your-deployed-api).\n",
    "\n",
    "Instead of creating a deployment instance for active learning on the Nexus platform, we can use the Datature Python SDK as a more convenient way to interact with Nexus. For more information on the Datature SDK, do check out our [SDK docs](https://developers.datature.io/reference/getting-started)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "This notebook assumes that you already have a trained model on [Datature Nexus](https://nexus.datature.io/). If not, you can follow this [tutorial](https://developers.datature.io/docs/building-your-first-model) to train your very own model!\n",
    "\n",
    "You will also need to create a hosted deployment and make inference calls using our [Inference API](https://www.datature.io/blog/how-to-use-api-deployment-for-trained-model-inference). API deployment is an add-on feature that can be enabled regardless of which subscription tier you are on. If you would like to sign up for API deployment, do [contact us](mailto:sales@datature.io) and we will be happy to help you get started."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install & Import Necessary Pip Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://asia-python.pkg.dev/datature-puppeteer/python/simple\n",
      "Requirement already satisfied: datature in /home/cwlroda/projects/puppeteer/env/lib/python3.10/site-packages (0.6.5)\n",
      "Requirement already satisfied: requests in /home/cwlroda/projects/puppeteer/env/lib/python3.10/site-packages (from datature) (2.28.1)\n",
      "Requirement already satisfied: google-crc32c in /home/cwlroda/projects/puppeteer/env/lib/python3.10/site-packages (from datature) (1.5.0)\n",
      "Requirement already satisfied: pyhumps in /home/cwlroda/projects/puppeteer/env/lib/python3.10/site-packages (from datature) (3.8.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/cwlroda/projects/puppeteer/env/lib/python3.10/site-packages (from requests->datature) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/cwlroda/projects/puppeteer/env/lib/python3.10/site-packages (from requests->datature) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/cwlroda/projects/puppeteer/env/lib/python3.10/site-packages (from requests->datature) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/cwlroda/projects/puppeteer/env/lib/python3.10/site-packages (from requests->datature) (3.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://asia-python.pkg.dev/datature-puppeteer/python/simple\n",
      "Requirement already satisfied: numpy in /home/cwlroda/projects/puppeteer/env/lib/python3.10/site-packages (1.24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U datature\n",
    "!pip3 install -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import datature\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Constants\n",
    "\n",
    "The project secret can be found in [API Management](https://developers.datature.io/docs/hub-and-api#locating-the-project-secret).\n",
    "\n",
    "As this implementation uses local files, the code has been written such that we convert to base64 first. We should be careful to use sufficiently small base64 text to fit the json request.\n",
    "\n",
    "The image type and image input has a few different options which you can check on our [docs](https://developers.datature.io/docs/making-api-calls-to-your-deployed-api).\n",
    "\n",
    "Feel free to change the values of the constants below for your own use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_SECRET = \"539037bcd03da96aebd90b134631d9541f919ecddcf0e99ddc4dc585f355c267\"\n",
    "\n",
    "IMAGE_FILE_PATH = \"image.png\"\n",
    "IMAGE_TYPE = \"base_64\"\n",
    "PREDICTIONS_FILE_PATH = \"predictions.csv\"\n",
    "\n",
    "## List of asset group names. Assets will be added to these asset groups upon upload.\n",
    "ASSET_GROUP = [\"active-learning-demo\"]\n",
    "\n",
    "## Average entropy threshold for active learning\n",
    "AVERAGE_ENTROPY_THRESHOLD = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Helper Functions\n",
    "\n",
    "`above_threshold` is a helper function that returns a boolean value indicating whether the average entropy value of any class is above the entropy threshold.\n",
    "\n",
    "`convert_predictions_to_4cornercsv` is a helper function that converts the predictions from the Inference API to a 4-corner CSV format that is accepted for upload to Nexus.\n",
    "\n",
    "`upload_image_to_nexus` is a helper function that uploads an image to Nexus using Datature SDK.\n",
    "\n",
    "`upload_predictions_to_nexus` is a helper function that uploads the 4-corner CSV  converted predictions as annotations to Nexus using Datature SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def above_threshold(json_resp):\n",
    "    \"\"\"Check if the average entropy of any class is above the threshold.\n",
    "\n",
    "    Args:\n",
    "        json_resp: JSON response containing the average entropy per class.\n",
    "\n",
    "    Returns:\n",
    "        True if the average entropy of any class is above the threshold, False otherwise.\n",
    "    \"\"\"\n",
    "    return np.any(\n",
    "        np.array(list(json_resp[\"avgPerClass\"].values())) >\n",
    "        AVERAGE_ENTROPY_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_predictions_to_4cornercsv(predict_json):\n",
    "    \"\"\"Writes the predictions JSON response to a CSV file in the 4-corner format.\n",
    "\n",
    "    Args:\n",
    "        json_resp: JSON response containing the predictions.\n",
    "    \"\"\"\n",
    "    with open(PREDICTIONS_FILE_PATH, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        ## Define the header\n",
    "        header = [\"filename\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"label\"]\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for prediction in predict_json[\"predictions\"]:\n",
    "            ## Only write predictions with confidence above the threshold\n",
    "            if prediction[\"confidence\"] >= AVERAGE_ENTROPY_THRESHOLD:\n",
    "                label = prediction[\"tag\"][\"name\"]\n",
    "                xmin = prediction[\"bound\"][0][0]\n",
    "                ymin = prediction[\"bound\"][0][1]\n",
    "                xmax = prediction[\"bound\"][2][0]\n",
    "                ymax = prediction[\"bound\"][2][1]\n",
    "                \n",
    "                row = [\n",
    "                    os.path.basename(IMAGE_FILE_PATH), xmin, ymin, xmax, ymax, label\n",
    "                ]\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_image_to_nexus():\n",
    "    \"\"\"Upload image to Nexus.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to image to be uploaded to Nexus.\n",
    "    \"\"\"\n",
    "    print(f\"Uploading image '{IMAGE_FILE_PATH}' to Nexus...\")\n",
    "    upload_session = datature.Asset.upload_session()\n",
    "    upload_session.add(IMAGE_FILE_PATH)\n",
    "    asset_upload_op_link = upload_session.start(cohorts=ASSET_GROUP, early_return=True)[\"op_link\"]\n",
    "\n",
    "    while datature.Operation.retrieve(asset_upload_op_link)[\"status\"][\n",
    "            \"progress\"][\"with_status\"][\"finished\"] != 1:\n",
    "        time.sleep(1)\n",
    "    print(f\"Uploaded image '{IMAGE_FILE_PATH}' to Nexus!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_predictions_to_nexus(predict_json):\n",
    "    \"\"\"Upload predictions to Nexus as annotations.\n",
    "\n",
    "    Args:\n",
    "        predict_json: JSON response containing the predictions.\n",
    "    \"\"\"\n",
    "    print(\n",
    "        f\"Uploading predictions for image '{IMAGE_FILE_PATH}' to platform...\")\n",
    "    convert_predictions_to_4cornercsv(predict_json)\n",
    "\n",
    "    annotation_upload_op_link = datature.Annotation.upload(\n",
    "        \"csv_fourcorner\", PREDICTIONS_FILE_PATH, early_return=True)[\"op_link\"]\n",
    "\n",
    "    while datature.Operation.retrieve(annotation_upload_op_link)[\"status\"][\n",
    "            \"progress\"][\"with_status\"][\"finished\"] != 1:\n",
    "        time.sleep(1)\n",
    "    print(f\"Uploaded predictions for image '{IMAGE_FILE_PATH}' to Nexus!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a New Deployment with a Trained Model\n",
    "\n",
    "You can obtain the details of all artifacts in your project and choose one based on the name or timestamp among other variables. You will need the artifact ID to select a model format for deployment. In this demo, we have exported our model in the ONNX format and obtained the model ID to be used for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact ID: artifact_63ea0006b03587e371e708cd\n",
      "Model ID: model_e83103efcb8c3a56cb17868cc55906a6\n"
     ]
    }
   ],
   "source": [
    "## Set the project secret\n",
    "datature.project_secret = PROJECT_SECRET\n",
    "\n",
    "## Obtain an artifact id from Nexus, in this case, we assume that there is only one artifact\n",
    "all_artifacts = datature.Artifact.list()\n",
    "artifact_id = all_artifacts[-1][\"id\"]\n",
    "\n",
    "## Obtain an exported model id from Nexus in ONNX format\n",
    "all_models = datature.Artifact.list_exported(artifact_id)\n",
    "model_id = [model for model in all_models\n",
    "            if model[\"format\"] == \"onnx\"][-1][\"id\"]\n",
    "\n",
    "print(f\"Artifact ID: {artifact_id}\")\n",
    "print(f\"Model ID: {model_id}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the model ID, we can create a deployment instance. We can use the Datature SDK to periodically poll for the status of the creation, and we print an output once the deployment has been successful. This may take a few minutes, so you can grab a cup of coffee in the meantime!\n",
    "\n",
    "Please note that multiple deployment instances can be created with the same name and model ID, and unintentionally running this code block multiple times may result in multiple deployments with the same name and model ID. If you would like to delete a deployment, you can do so in the [API Management](https://developers.datature.io/docs/making-api-calls-to-your-deployed-api#deleting-your-deployment) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a model deployment using the model id obtained earlier\n",
    "deploy_create_response = datature.Deploy.create({\n",
    "    \"name\": \"Active Learning Deployment\",\n",
    "    \"model_id\": model_id,\n",
    "    \"num_of_instances\": 1,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployed model to Datature Inference API!\n"
     ]
    }
   ],
   "source": [
    "## Wait for the model deployment to be ready\n",
    "while datature.Operation.retrieve(\n",
    "        deploy_create_response[\"op_link\"])[\"status\"][\"overview\"] != \"Finished\":\n",
    "    time.sleep(5)\n",
    "print(\"Deployed model to Datature Inference API!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment ID: deploy_f5f49be7-aaf6-4558-9445-f0ac0a51db1b\n",
      "API URL: https://inference.datature.io/neural/f5f49be7-aaf6-4558-9445-f0ac0a51db1b/predict\n"
     ]
    }
   ],
   "source": [
    "## Obtain the API URL of the model deployment\n",
    "active_learning_deployment = [\n",
    "    deployment for deployment in datature.Deploy.list()\n",
    "    if deployment[\"name\"] == \"Active Learning Deployment\"\n",
    "][-1]\n",
    "\n",
    "deployment_id = active_learning_deployment[\"id\"]\n",
    "API_URL = active_learning_deployment[\"url\"]\n",
    "\n",
    "print(f\"Deployment ID: {deployment_id}\")\n",
    "print(f\"API URL: {API_URL}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Image for Inference\n",
    "\n",
    "For this demo, we load the image as a base64 string However, you can load the image in other formats as described in the table below.\n",
    "\n",
    "| Image Type | Data | Example |\n",
    "| --- | --- | --- | \n",
    "| url | String containing your URL | image_input = \"<YOUR_IMAGE_PATH>\" |\n",
    "| base64 | String containing your base64 image encoding | with open(<YOUR_IMAGE_PATH>, \"rb\") <br /> &emsp;&emsp;base64_byte = base64.b64encode(img_file.read()) <br /> &emsp;&emsp;image_input = base64_byte.decode(\"utf-8\") |\n",
    "| array | Nested array representing your image data in array form | image_input = np.array(PIL.Image.open(<YOUR_IMAGE_PATH>)) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "with open(IMAGE_FILE_PATH, \"rb\") as img_file:\n",
    "    base64_byte = base64.b64encode(img_file.read())\n",
    "    image_input = base64_byte.decode(\"utf-8\")\n",
    "img_file.close()\n",
    "\n",
    "print(type(image_input))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Payload and Headers for the Inference API Request\n",
    "\n",
    "The prediction payload is used to make an inference call to obtain prediction results. The payload with active learning is used to make an inference call to obtain active learning entropy values for the predictions. The headers are used to authenticate the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_payload = {\n",
    "    \"image_type\": IMAGE_TYPE,\n",
    "    \"data\": image_input,\n",
    "}\n",
    "\n",
    "payload_with_active_learning = {\n",
    "    \"image_type\":\n",
    "    IMAGE_TYPE,\n",
    "    \"data\":\n",
    "    image_input,\n",
    "    \"routines\": [\n",
    "        {\n",
    "            \"name\": \"ActiveLearningMetric\",\n",
    "            \"arguments\": {\n",
    "                \"class_name\": [\"Platelets\", \"RBC\", \"WBC\"],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + PROJECT_SECRET,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the Prediction Results of the Image\n",
    "\n",
    "The prediction results are returned as a json object with the following fields:\n",
    "\n",
    "#### For Object Detection Bounding Box Models\n",
    "\n",
    " - `annotation_id`: Running index of annotation\n",
    " - `bound`: Bounding box `x,y` coordinates in the format of\n",
    "    ```\n",
    "    [ [xmin, ymin], [xmin, ymax], [xmax, ymax], [xmax, ymin] ]\n",
    "    ```\n",
    " - `boundType`: Type of prediction shape from model output. Can be either rectangle or polygon\n",
    " - `confidence`: Prediction confidence percentage\n",
    " - `tag`: Object containing class label information that includes\n",
    "   - `id`: Index of class label according to model tag map\n",
    "   - `name`: Name of class label assigned to the prediction\n",
    "\n",
    "#### Additional Information for Segmentation Mask Models\n",
    "\n",
    "- `contourType`: Output format of segmentation predictions\n",
    "- `contour`: Polygonal `x, y` coordinates in the format of\n",
    "  ```\n",
    "  [ [x1, y1], [x2, y2], [x3, y3], ... [xn, yn] ]\n",
    "  ```\n",
    "  where n is the number of polygon vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Output:\n",
      "==================\n",
      "{'predictions': [{'annotationId': 0,\n",
      "                  'bound': [[0.2666337490081787, 0.08433949947357178],\n",
      "                            [0.2666337490081787, 1.0],\n",
      "                            [1.0, 1.0],\n",
      "                            [1.0, 0.08433949947357178]],\n",
      "                  'boundType': 'rectangle',\n",
      "                  'confidence': 0.7772380709648132,\n",
      "                  'contour': None,\n",
      "                  'contourType': None,\n",
      "                  'tag': {'id': 2, 'name': 'RBC'}},\n",
      "                 {'annotationId': 1,\n",
      "                  'bound': [[0.17402619123458862, 0.0],\n",
      "                            [0.17402619123458862, 0.9257490634918213],\n",
      "                            [1.0, 0.9257490634918213],\n",
      "                            [1.0, 0.0]],\n",
      "                  'boundType': 'rectangle',\n",
      "                  'confidence': 0.770164430141449,\n",
      "                  'contour': None,\n",
      "                  'contourType': None,\n",
      "                  'tag': {'id': 2, 'name': 'RBC'}},\n",
      "                 {'annotationId': 2,\n",
      "                  'bound': [[0.0691288411617279, 0.17821002006530762],\n",
      "                            [0.0691288411617279, 1.0],\n",
      "                            [1.0, 1.0],\n",
      "                            [1.0, 0.17821002006530762]],\n",
      "                  'boundType': 'rectangle',\n",
      "                  'confidence': 0.7631288766860962,\n",
      "                  'contour': None,\n",
      "                  'contourType': None,\n",
      "                  'tag': {'id': 2, 'name': 'RBC'}},\n",
      "                 {'annotationId': 3,\n",
      "                  'bound': [[0.8318424820899963, 0.0],\n",
      "                            [0.8318424820899963, 0.23213404417037964],\n",
      "                            [1.0, 0.23213404417037964],\n",
      "                            [1.0, 0.0]],\n",
      "                  'boundType': 'rectangle',\n",
      "                  'confidence': 0.7314205765724182,\n",
      "                  'contour': None,\n",
      "                  'contourType': None,\n",
      "                  'tag': {'id': 1, 'name': 'WBC'}},\n",
      "                 {'annotationId': 4,\n",
      "                  'bound': [[0.7927815318107605, 0.02345915138721466],\n",
      "                            [0.7927815318107605, 0.26011425256729126],\n",
      "                            [0.9673344492912292, 0.26011425256729126],\n",
      "                            [0.9673344492912292, 0.02345915138721466]],\n",
      "                  'boundType': 'rectangle',\n",
      "                  'confidence': 0.5592967867851257,\n",
      "                  'contour': None,\n",
      "                  'contourType': None,\n",
      "                  'tag': {'id': 1, 'name': 'WBC'}},\n",
      "                 {'annotationId': 5,\n",
      "                  'bound': [[0.7554447650909424, 0.0],\n",
      "                            [0.7554447650909424, 0.229902982711792],\n",
      "                            [0.933457612991333, 0.229902982711792],\n",
      "                            [0.933457612991333, 0.0]],\n",
      "                  'boundType': 'rectangle',\n",
      "                  'confidence': 0.4409312605857849,\n",
      "                  'contour': None,\n",
      "                  'contourType': None,\n",
      "                  'tag': {'id': 1, 'name': 'WBC'}}]}\n"
     ]
    }
   ],
   "source": [
    "## Send a POST request to the API URL with the image payload\n",
    "response = requests.post(\n",
    "    API_URL,\n",
    "    json=prediction_payload,\n",
    "    headers=headers,\n",
    ")\n",
    "\n",
    "## Obtain the JSON response containing the predictions\n",
    "predict_json = response.json()\n",
    "print(\"Prediction Output:\")\n",
    "print(\"==================\")\n",
    "pprint(predict_json)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the Entropy Values of the Prediction Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Entropy Values Per Class (lower is better):\n",
      "===================================================\n",
      "{'avgPerClass': {'Platelets': 0.0,\n",
      "                 'RBC': 0.777565731453065,\n",
      "                 'WBC': 0.9397180680879296},\n",
      " 'totalEntropy': 5.151851398622984}\n"
     ]
    }
   ],
   "source": [
    "## Send a POST request to the API URL with the image payload and active learning routine\n",
    "response = requests.post(\n",
    "    API_URL,\n",
    "    json=payload_with_active_learning,\n",
    "    headers=headers,\n",
    ")\n",
    "\n",
    "## Obtain the JSON response containing the entropy values for each class\n",
    "json_resp = response.json()\n",
    "print(\"Average Entropy Values Per Class (lower is better):\")\n",
    "print(\"===================================================\")\n",
    "pprint(json_resp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the Image and Predictions to Nexus if the Average Entropy Exceeds the Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Entropy value(s) below threshold\n",
      "Uploading image 'image.png' to Nexus...\n",
      "Uploaded image 'image.png' to Nexus!\n",
      "Uploading predictions for image 'image.png' to platform...\n",
      "Uploaded predictions for image 'image.png' to Nexus!\n"
     ]
    }
   ],
   "source": [
    "if above_threshold(json_resp):\n",
    "    print(\"Warning: Entropy value(s) below threshold\")\n",
    "    upload_image_to_nexus()\n",
    "    upload_predictions_to_nexus(predict_json)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Deployment (Optional)\n",
    "\n",
    "If you are no longer using your deployment instance, you can delete it to free up resources used by the deployment instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted deployment instance!\n"
     ]
    }
   ],
   "source": [
    "deploy_delete_response = datature.Deploy.delete(deployment_id)\n",
    "\n",
    "if deploy_delete_response[\"deleted\"] == True:\n",
    "    print(\"Deleted deployment instance!\")\n",
    "else:\n",
    "    print(\"Failed to delete deployment instance!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de9672c09571d0a778bd149d8a2a57066ba7df688cb3e2d31b492d87d16de9e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

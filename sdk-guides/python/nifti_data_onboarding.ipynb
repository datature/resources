{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# -*-coding:utf-8 -*-\n",
        "'''\n",
        "  ████\n",
        "██    ██   Datature\n",
        "  ██  ██   Powering Breakthrough AI\n",
        "    ██\n",
        "\n",
        "@File    :   nifti_data_onboarding.ipynb\n",
        "@Author  :   Trevor Carrell\n",
        "@Version :   1.0\n",
        "@Contact :   hello@datature.io\n",
        "@License :   Apache License 2.0\n",
        "@Desc    :   Demo for uploading NiFTI files using Datature Python SDK\n",
        "             and converting bitmask annotations to COCO polygon annotation\n",
        "             files.\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGf3OfA6qYVm"
      },
      "source": [
        "# Creating a COCO formatted file using an RLE Mask for object annotation via `.nii` file uploading.\n",
        "In this python notebook, we will be using `.nii` files and their corresponding labels to create a COCO formatted file which allows Datature users to upload their `.nii` files and labels to create a COCO formatted file, which will annotate their uploaded files.\n",
        "\n",
        "## Uploading testing files to Nexus using Datature SDK:\n",
        "Before we start creating our COCO formatted file, we first need to upload our `.nii` files onto Nexus. To do so, we will utilize Datature's SDK, which converts our `.nii` files to `.mp4` files. Note that this conversion is necessary to allow for interpolation when using the annotation tool in Nexus.\n",
        "\n",
        "### Install / Import necessary libaries:\n",
        "In this python notebook, we will be using a few libraries to perform the task at hand. We do this below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDqj8YLsqYVo",
        "outputId": "7dfd8304-5c5f-4ff7-e7a1-9b1c1247d6e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (23.3.1)\n",
            "Requirement already satisfied: datature in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.4.0)\n",
            "Requirement already satisfied: requests==2.28.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datature) (2.28.1)\n",
            "Requirement already satisfied: google-crc32c==1.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datature) (1.5.0)\n",
            "Requirement already satisfied: pyhumps==3.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datature) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datature) (6.0.1)\n",
            "Requirement already satisfied: inquirer>=2.10.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datature) (3.1.4)\n",
            "Requirement already satisfied: halo==0.0.31 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datature) (0.0.31)\n",
            "Requirement already satisfied: filetype==1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datature) (1.2.0)\n",
            "Requirement already satisfied: opencv-python==4.7.0.72 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datature) (4.7.0.72)\n",
            "Requirement already satisfied: alive-progress==3.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datature) (3.0.1)\n",
            "Requirement already satisfied: pydicom==2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datature) (2.3.1)\n",
            "Requirement already satisfied: nibabel>=4.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datature) (5.1.0)\n",
            "Requirement already satisfied: matplotlib>=3.5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datature) (3.8.2)\n",
            "Requirement already satisfied: about-time==4.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from alive-progress==3.0.1->datature) (4.2.1)\n",
            "Requirement already satisfied: grapheme==0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from alive-progress==3.0.1->datature) (0.6.0)\n",
            "Requirement already satisfied: log-symbols>=0.0.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from halo==0.0.31->datature) (0.0.14)\n",
            "Requirement already satisfied: spinners>=0.0.24 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from halo==0.0.31->datature) (0.0.24)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from halo==0.0.31->datature) (2.3.0)\n",
            "Requirement already satisfied: colorama>=0.3.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from halo==0.0.31->datature) (0.4.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /Users/trevorcarrell/Library/Python/3.12/lib/python/site-packages (from halo==0.0.31->datature) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opencv-python==4.7.0.72->datature) (1.26.2)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests==2.28.1->datature) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests==2.28.1->datature) (3.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests==2.28.1->datature) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests==2.28.1->datature) (2023.11.17)\n",
            "Requirement already satisfied: blessed>=1.19.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from inquirer>=2.10.1->datature) (1.20.0)\n",
            "Requirement already satisfied: python-editor>=1.0.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from inquirer>=2.10.1->datature) (1.0.4)\n",
            "Requirement already satisfied: readchar>=3.0.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from inquirer>=2.10.1->datature) (4.0.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=3.5.3->datature) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=3.5.3->datature) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=3.5.3->datature) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=3.5.3->datature) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/trevorcarrell/Library/Python/3.12/lib/python/site-packages (from matplotlib>=3.5.3->datature) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=3.5.3->datature) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=3.5.3->datature) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/trevorcarrell/Library/Python/3.12/lib/python/site-packages (from matplotlib>=3.5.3->datature) (2.8.2)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /Users/trevorcarrell/Library/Python/3.12/lib/python/site-packages (from blessed>=1.19.0->inquirer>=2.10.1->datature) (0.2.12)\n",
            "Requirement already satisfied: setuptools>=41.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from readchar>=3.0.6->inquirer>=2.10.1->datature) (69.0.2)\n",
            "Requirement already satisfied: nibabel in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (5.1.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nibabel) (1.26.2)\n",
            "Requirement already satisfied: packaging>=17 in /Users/trevorcarrell/Library/Python/3.12/lib/python/site-packages (from nibabel) (23.2)\n",
            "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/trevorcarrell/Library/Python/3.12/lib/python/site-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/trevorcarrell/Library/Python/3.12/lib/python/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/trevorcarrell/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.26.2)\n",
            "Requirement already satisfied: pycocotools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.0.7)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pycocotools) (3.8.2)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pycocotools) (1.26.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/trevorcarrell/Library/Python/3.12/lib/python/site-packages (from matplotlib>=2.1.0->pycocotools) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/trevorcarrell/Library/Python/3.12/lib/python/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/trevorcarrell/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/google_crc32c/__init__.py:29: RuntimeWarning: As the c extension couldn't be imported, `google-crc32c` is using a pure python implementation that is significantly slower. If possible, please configure a c build environment and compile the extension\n",
            "  warnings.warn(_SLOW_CRC32C_WARNING, RuntimeWarning)\n"
          ]
        }
      ],
      "source": [
        "# Handle installation of packages.\n",
        "! pip3 install --upgrade pip       # Upgrade pip.\n",
        "! pip3 install --upgrade datature  # Install and update datature package.\n",
        "! pip3 install nibabel             # Install nibabel package.\n",
        "! pip3 install -U matplotlib       # Install matplotlib package.\n",
        "! pip3 install numpy               # Install numpy package.\n",
        "! pip3 install pycocotools         # Install pycocotools package.\n",
        "\n",
        "# Handle imports.\n",
        "import os\n",
        "from pycocotools import mask\n",
        "import glob\n",
        "import datature as dt\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime, timezone\n",
        "import time\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B34YycWSqYVp"
      },
      "source": [
        "### Define data paths and project secret key variables:\n",
        "Now that we've imported the necessary libraries, we should define the path which will contain our `.nii` files and labels, the path that we want to output our COCO formatted file, and our projects secret key (which is necessary to use Datature's SDK).\n",
        "\n",
        "When using on your machine, replace `DATA_PATH` with the path to your `.nii` labels, the `OUTPUT_PATH` to where you want to output to go, and `dt.secret_key` with your project's secret key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynQgaYI9qYVp"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"/Users/trevorcarrell/Documents/Datature.nosync/nii to COCO Format Code/Medical AI Series/Dataset\"   # Path to data.\n",
        "OUTPUT_PATH = \"/Users/trevorcarrell/Documents/Datature.nosync/nii to COCO Format Code/Medical AI Series/output\"  # Path to output.\n",
        "\n",
        "# If you're unsure how to get your secret key, check out the information below this cell.\n",
        "dt.secret_key = \"4990dc9ed87107f5d680dc379570009438680945d83c150bc8fcfa4969d598d3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ24bVVhqYVp"
      },
      "source": [
        "### Data sanity checks:\n",
        "Now, before we continue, it's always good practice to ensure our `.nii` files and their labels have the same dimensions, and that we have the same number of each (for one `.nii` file, we need a label file)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxiGlMM0qYVp"
      },
      "outputs": [],
      "source": [
        "data_files = glob.glob(\"*.nii\", root_dir=f'{DATA_PATH}/t1gd')  # Get all data files.\n",
        "label_files = glob.glob(\"*.nii\", root_dir=f'{DATA_PATH}/labels/original')  # Get all label files.\n",
        "\n",
        "# Ensure that we have the same number of data files and label files, and ensure that these files exist.\n",
        "assert len(data_files) > 0 and len(label_files) > 0, \"Data and labels directories must not be empty.\"\n",
        "assert len(data_files) == len(label_files), \"Number of data files and label files must be equal.\"\n",
        "\n",
        "# Ensure that each data file has a label file. Our naming schema is that the label file is the same name\n",
        "# as the data file, the first character is a \"l\".\n",
        "for file in data_files:\n",
        "\n",
        "    # Create the label file name we expect.\n",
        "    label_filepath = os.path.join(f'{DATA_PATH}/labels/original', f'l{file[1:]}')\n",
        "\n",
        "    # Ensure that the label file exists.\n",
        "    assert os.path.exists(label_filepath), f\"Label file {label_filepath} does not exist.\"\n",
        "\n",
        "    # Load the label file and data file.\n",
        "    label_file = nib.load(label_filepath)\n",
        "    data_file = nib.load(os.path.join(f'{DATA_PATH}/t1gd', file))\n",
        "\n",
        "    # Ensure that the label file and data file have the same shape.\n",
        "    assert label_file.shape == data_file.shape, f\"Label file {label_file} does not match data file {data_file}.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQk8HcTxqYVq"
      },
      "source": [
        "### Generating your project's secret key:\n",
        "*Courtesy of Hoki*\n",
        "\n",
        "The steps are as follows:\n",
        "\n",
        "1. Sign up for a free Datature account at https://www.datature.io\n",
        "2. Create a new project on Nexus\n",
        "3. Go to the Integrations page\n",
        "4. Choose `Generate New Secret` to get your Secret Key\n",
        "5. Follow this script to use Datature SDK to upload the NifTi files to Nexus\n",
        "\n",
        "For more information about Datature's Python SDK, see https://developers.datature.io/docs/python-sdk.\n",
        "\n",
        "### Uploading `.nii` files to Datature Nexus:\n",
        "Note that for `.nii` files, each file is a separate 3D volume.\n",
        "\n",
        "* If the axis of orientation is provided, the SDK will upload a series of 2D slices corresponding to the specified orientation. Thus, you will only see one asset on Nexus which contains the 2D slices.\n",
        "\n",
        "* If the axis of orientation is **not** provided, the SDK will upload a series of 2D slices for each orientation (x, y, and z). Thus, you will see three assets on Nexus which contain the 2D slices using the axial (z orientation), coronal (y orientation), and sagittal (x orientation) planes.\n",
        "\n",
        "With that, we can begin.\n",
        "\n",
        "### Uploading our dataset using Datature's SDK\n",
        "To use Datature's SDK, we need to first create an `UploadSession` class. The `UploadSession` class is designed with two methods, `.add()` and `.start()`.\n",
        "\n",
        "* `.add()` adds local files to our `UploadSession` class,\n",
        "\n",
        "* `.start()` calls the Datature server's to start uploading the assets we've added.\n",
        "\n",
        "\n",
        "**Note that we only want to upload our `.nii` files and not the labels.**\n",
        "\n",
        "***!!! Uploading may take awhile !!!*** – have waited at most three and a half minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FV46U31vqYVq",
        "outputId": "38157d01-8b79-474c-c051-797cd3773aee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Uploading files...\n",
            "Finished uploading 10 files to Datature Nexus.\n"
          ]
        }
      ],
      "source": [
        "# Create an upload session using the Datature API.\n",
        "upload_session = dt.Asset.upload_session()\n",
        "\n",
        "# Initialize number of files uploaded.\n",
        "files_uploaded = 0\n",
        "# Now, we'll loop through the assets in the data directory and add them to the upload session.\n",
        "for file in glob.glob(f'{DATA_PATH}/t1gd/*.nii'):\n",
        "\n",
        "    # Add the asset to the upload session, specifying the orientation as 'z'.\n",
        "    upload_session.add(file, orientation='z')\n",
        "    files_uploaded += 1\n",
        "\n",
        "# Check to make sure that the path we specified contained files.\n",
        "assert files_uploaded > 0, 'No files were uploaded. Please check your data path.'\n",
        "\n",
        "# Now that we've added all of the assets to the upload session, we can start uploading them to Datature.\n",
        "op_link = upload_session.start(background=True)['op_link']\n",
        "\n",
        "# We can check the status of the upload session by calling the .retrieve() method.\n",
        "while dt.Operation.retrieve(op_link)['status']['progress']['with_status']['finished'] != files_uploaded:\n",
        "    print(f'Uploading files...')\n",
        "    time.sleep(1)  # We sleep here to keep incrementally checking on our upload status, as well as to prevent spamming the API.\n",
        "\n",
        "print(f'Finished uploading {files_uploaded} files to Datature Nexus.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAIEDXyXqYVq"
      },
      "source": [
        "## Creating COCO formatted file from `.nii` files and labels:\n",
        "Now that we have uploaded our files to Nexus, we want to create annotations for those files using a run-length encoding (RLE) binary mask. To do so, we use the names of the files we created to create our COCO formatted file. ***Ultimately, we do not need to process each 2D slice to get the names of the files, so we can simply make a list or structure format for our files that we uploaded to Nexus***\n",
        "\n",
        "### More about our `.nii` files and their processing:\n",
        "Note that each of our `.nii` files are `(240, 240, 155)`, where the orientation is along the z-axis, meaning that we have 155 slices and each slice is `(240, 240)`. When converting to `.mp4`, this means that we create a video which runs through 155 frames of size `240px, 240px`.\n",
        "\n",
        "For a given `.nii` file, i.e. `d_0001.nii`, that file was uploaded to Nexus as a `.mp4` file named `d_0001-z.mp4`. We then represent each frame of the video file as it's own `.jpg` file, which is referred to as `d_0001-z#frame=[x].jpg`, where `[x]` is replaced with a frame numbered 0 to 154, inclusive.\n",
        "\n",
        "Also note that the `.nii` label files are `.nii` files themselves, but only contain the `category_id`'s for our identifable classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7NV-mhTqYVr"
      },
      "source": [
        "### Creating our COCO formatted file:\n",
        "Since our `.nii` files are stored in the Nexus, we can start building our COCO formatted file using the names of the files we uploaded with naming scheme above.\n",
        "\n",
        "There are a few considerations taken into account when making the COCO formatted file:\n",
        "\n",
        "* We assume the file format is similar to the format described here: https://developers.datature.io/docs/uploading-annotations#coco-annotator-polygons--masks\n",
        "\n",
        "* We use run-length encoding (RLE) binary masks for each `.nii` slice to create `n` separate masks for each slice, where `n` is the number of classes. In our case, we have `n = 3` classes: `non-enhancing tumor`, `enhancing tumor`, `edema`. The absence of a class indicates the brain region is unafflicted.\n",
        "\n",
        "Now, we create the COCO formatted file as a dictionary, then conver it to a `.json` file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYwbMpZwqYVr"
      },
      "outputs": [],
      "source": [
        "NUM_IMAGES = 155  # Number of images per .nii file.\n",
        "\n",
        "\n",
        "def create_rle_mask(mask_data: np.ndarray[int]) -> dict:\n",
        "    \"\"\"\n",
        "    Given a binary mask, we create the RLE mask.\n",
        "\n",
        "    Input:\n",
        "        mask_data (ndarray): binary mask\n",
        "\n",
        "    Output:\n",
        "        rle_mask (ndarray): RLE binary mask\n",
        "    \"\"\"\n",
        "\n",
        "    # Since the RLE mask requires a fortran array, we need to encode the mask_data as a fortran array.\n",
        "    rle_data = mask.encode(np.asfortranarray(mask_data).astype(np.uint8))\n",
        "\n",
        "    # Now we create the RLE mask using the string encoding of the bytes.\n",
        "    rle_mask = {'counts': rle_data['counts'].decode('ascii'), 'size': rle_data['size']}\n",
        "\n",
        "    return rle_mask\n",
        "\n",
        "\n",
        "def create_licenses_entry() -> list[dict]:\n",
        "    return [{'id': 0,\n",
        "             'name': \"Unknown\",\n",
        "             'url': \"\"}]\n",
        "\n",
        "\n",
        "def create_info_entry() -> dict:\n",
        "    return {'description': 'Datature Created COCO Format Dataset',\n",
        "            'url': '',\n",
        "            'version': 1,\n",
        "            'year': datetime.now(timezone.utc).strftime('%Y'),\n",
        "            'contributor': 'Datature',\n",
        "            'date_created': datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f%z')}\n",
        "\n",
        "\n",
        "def create_annotation_entry(curr_image_id: int, curr_annotation_id: int, category_id: int, rle_mask: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Given the current image id, current annotation id, category id, and rle mask, we create the annotation entry.\n",
        "\n",
        "    Input:\n",
        "        curr_image_id (int): current image id\n",
        "        curr_annotation_id (int): current annotation id\n",
        "        category_id (int): category id\n",
        "        rle_mask (dict): RLE binary mask where the keys are 'counts' and 'size'.\n",
        "\n",
        "    Output:\n",
        "        annotation_entry (dict): annotation entry\n",
        "    \"\"\"\n",
        "    return {'id': curr_annotation_id,\n",
        "            'image_id': curr_image_id,\n",
        "            'category_id': category_id,\n",
        "            'segmentation': rle_mask,\n",
        "            'area': 0,\n",
        "            'bbox': [0, 0, 0, 0],\n",
        "            'iscrowd': 1}\n",
        "\n",
        "\n",
        "def create_image_entry(filename: str, img_shape: tuple[int, int], curr_image_id: int) -> dict:\n",
        "    \"\"\"\n",
        "    Given the filename, image shape, and current image id, we create the image entry.\n",
        "\n",
        "    Input:\n",
        "        filename (string): filename of the image\n",
        "        img_data (tuple): image shape, which is a tuple of the image's width and height\n",
        "        curr_image_id (int): current image id\n",
        "\n",
        "    Output:\n",
        "        image_entry (dict): image entry\n",
        "    \"\"\"\n",
        "    return {'id': curr_image_id,\n",
        "            'width': img_shape[0],\n",
        "            'height': img_shape[1],\n",
        "            'file_name': filename,\n",
        "            'license': 0,\n",
        "            'date_captured': datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f%z')}\n",
        "\n",
        "\n",
        "def create_coco_json(nii_labels_path: str, classes: dict[str, int]) -> dict:\n",
        "    \"\"\"\n",
        "    Given the original nii_path, which is a directory to .nii label files, and the output_path, which we stored our updated\n",
        "    binary masks, we create a COCO format json file.\n",
        "\n",
        "    Input:\n",
        "        nii_labels_path (string): path to directory containing .nii files\n",
        "        output_path (string): path to directory where you want to save the numpy arrays\n",
        "        classes (list): list of classes in the dataset\n",
        "\n",
        "    Output:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the items in the COCO json file.\n",
        "    info = create_info_entry()\n",
        "    images = []\n",
        "    categories = [{'supercategory': key, 'id': val, 'name': key} for key, val in classes.items()]\n",
        "    annotations = []\n",
        "    licenses = create_licenses_entry()\n",
        "\n",
        "    # Use to keep track of the image id.\n",
        "    curr_image_id = 0\n",
        "    curr_annotation_id = 0\n",
        "\n",
        "    # Now we create annotations from each image's binary mask (located in output directory); simutaneously, we create the RLEs\n",
        "    for file in glob.glob(f'*.nii', root_dir=nii_labels_path):  # We specify root here since we use the the filename later.\n",
        "\n",
        "        # Load in the .nii file, create ndarray of the data.\n",
        "        nii_mask = nib.load(os.path.join(nii_labels_path, f'{file}'))\n",
        "        nii_mask_data = nii_mask.get_fdata()\n",
        "\n",
        "        # Go through each frame in the .nii label file and create its RLE binary mask.\n",
        "        for i in range(nii_mask_data.shape[2]):\n",
        "\n",
        "            # Add the image entry in the images dictionary (remember to add the frame number to the filename and orientation).\n",
        "            images.append(create_image_entry(f'd{file[1:-4]}-z#frame={i}.jpg', nii_mask_data[:, :, i].shape, curr_image_id))\n",
        "\n",
        "            # Now create the rle binary mask for each of the classes (not background) in the current frame.\n",
        "            for _, val in classes.items():\n",
        "                rle_mask_data = create_rle_mask(np.where(nii_mask_data[:, :, i] == val, 1, 0))\n",
        "                annotations.append(create_annotation_entry(curr_image_id, curr_annotation_id, val, rle_mask_data))\n",
        "                curr_annotation_id += 1\n",
        "\n",
        "            curr_image_id += 1\n",
        "\n",
        "    return {'info': info,\n",
        "            'images': images,\n",
        "            'annotations': annotations,\n",
        "            'categories': categories,\n",
        "            'licenses': licenses}\n",
        "\n",
        "\n",
        "# Now we begin creating our COCO format json file using the labels and classes for each image. Note that this function is\n",
        "# specific to the dataset we are working with, so it will need to be modified for different datasets. To see this, not that we\n",
        "# explicitly name the image entry by assuming a specific naming convention for our .nii files:\n",
        "#\n",
        "#             images.append(create_image_entry(f'd{file[1:-4]}-z#frame={i}.jpg', nii_mask_data[:, :, i], curr_image_id))\n",
        "#\n",
        "coco_dict = create_coco_json(f'{DATA_PATH}/labels/original', {'edema': 1, 'non-enhancing tumor': 2,'enhancing tumor': 3})\n",
        "\n",
        "# Save the coco_dict as a json file.\n",
        "with open(os.path.join(f'{OUTPUT_PATH}', 'coco.json'), 'w') as f:\n",
        "    json.dump(coco_dict, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CV6YfLCqYVs"
      },
      "source": [
        "## Culmination\n",
        "Ultimately, after running the last cell, we should have a COCO formatted `.json` file named `coco.json` in our `OUTPUT_PATH` directory, which can be uploaded using Nexus' Upload / Export Annotations feature.\n",
        "\n",
        "Here, when uploading, remember to specify that we are importing a file of format `[Polygon / Mask] COCO Mask` since we used an RLE binary mask."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
